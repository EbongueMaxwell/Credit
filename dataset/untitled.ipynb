import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.feature_selection import mutual_info_classif
import pickle
import logging
from IPython.display import display

# Configure Jupyter and logging
%matplotlib inline
logging.basicConfig(filename='scoring_errors.log', level=logging.ERROR)
pd.set_option('display.max_columns', None)

# Load the dataset
print("Loading data...")
try:
    df = pd.read_csv('credit_dataset_200000_rows.csv')
    print(f"Data loaded successfully. Shape: {df.shape}")
except Exception as e:
    print(f"Error loading data: {e}")
    raise

# Create target variable
df['status'] = (df['avg_days_late_current'] > 0).astype(int)
print("\nTarget variable created. Distribution:")
print(df['status'].value_counts(normalize=True))

# Define feature columns
num_cols = ['age', 'income', 'loan_amount', 'interest_rate', 'turnover', 
            'customer_tenure', 'avg_days_late_current', 'num_late_payments_current', 
            'unpaid_amount']
cat_cols = ['industry_sector', 'credit_type', 'has_guarantee', 'guarantee_type', 
            'repayment_frequency']

# Visualizations
print("\nGenerating visualizations...")
plt.figure(figsize=(15, 10))
df[num_cols].hist(bins=20)
plt.tight_layout()
plt.show()

for col in cat_cols:
    plt.figure(figsize=(10, 4))
    sns.countplot(data=df, x=col)
    plt.xticks(rotation=45)
    plt.show()

# Prepare data
X = df.drop(['status', 'application_date'], axis=1)
y = df['status']

# Label encode categorical variables
label_encoders = {}
for col in cat_cols:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col].astype(str))
    label_encoders[col] = le

# Mutual Information Calculation with proper feature names
print("\nCalculating Mutual Information...")
preprocessor_for_mi = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), num_cols),
        ('cat', OneHotEncoder(), cat_cols)
    ],
    remainder='drop',
    verbose_feature_names_out=False
)

X_mi = preprocessor_for_mi.fit_transform(X)
feature_names = preprocessor_for_mi.get_feature_names_out()

mi_scores = mutual_info_classif(X_mi, y)
mi_scores = pd.Series(mi_scores, name="MI Scores", index=feature_names).sort_values(ascending=False)

plt.figure(figsize=(12, 6))
mi_scores.plot(kind='bar')
plt.title("Mutual Information Scores")
plt.ylabel("Importance")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Correlation matrix
plt.figure(figsize=(12, 8))
sns.heatmap(df[num_cols + ['status']].corr(), annot=True, cmap='coolwarm', center=0)
plt.title("Correlation Matrix")
plt.show()

# Model Pipeline
numeric_features = num_cols
categorical_features = cat_cols

numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])
categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ],
    remainder='drop'
)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Logistic Regression
print("\nTraining Logistic Regression...")
lr_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(class_weight='balanced', random_state=42))
])
lr_pipeline.fit(X_train, y_train)

y_pred_lr = lr_pipeline.predict(X_test)
y_proba_lr = lr_pipeline.predict_proba(X_test)[:, 1]

print("\nLogistic Regression Performance:")
print(classification_report(y_test, y_pred_lr))

# Decision Tree
print("\nTraining Decision Tree...")
dt_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', DecisionTreeClassifier(random_state=42))
])
dt_pipeline.fit(X_train, y_train)

y_pred_dt = dt_pipeline.predict(X_test)
y_proba_dt = dt_pipeline.predict_proba(X_test)[:, 1]

print("\nDecision Tree Performance:")
print(classification_report(y_test, y_pred_dt))

# Hyperparameter Tuning
print("\nTuning Decision Tree...")
param_grid = {
    'classifier__max_depth': [3, 5, 7, 10, None],
    'classifier__min_samples_split': [2, 5, 10],
    'classifier__criterion': ['gini', 'entropy']
}
grid_search = GridSearchCV(dt_pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)
grid_search.fit(X_train, y_train)

best_dt = grid_search.best_estimator_
y_pred_best_dt = best_dt.predict(X_test)
y_proba_best_dt = best_dt.predict_proba(X_test)[:, 1]

print("\nOptimized Decision Tree Performance:")
print(classification_report(y_test, y_pred_best_dt))
print("Best parameters:", grid_search.best_params_)

# Model Comparison
results = pd.DataFrame({
    'Model': ['Logistic Regression', 'Decision Tree', 'Optimized Decision Tree'],
    'AUC': [
        roc_auc_score(y_test, y_proba_lr),
        roc_auc_score(y_test, y_proba_dt),
        roc_auc_score(y_test, y_proba_best_dt)
    ]
})
print("\nModel Comparison:")
display(results)

# Save models
print("\nSaving models...")
with open('credit_scoring_model.pkl', 'wb') as f:
    pickle.dump(lr_pipeline, f)

model_columns = {
    'numeric_features': numeric_features,
    'categorical_features': categorical_features,
    'label_encoders': label_encoders
}
with open('model_columns.pkl', 'wb') as f:
    pickle.dump(model_columns, f)

# Scoring Functions
RISK_LEVELS = [
    (800, "Very Low", "Approve with best terms and lowest rates"),
    (700, "Low", "Approve with favorable terms"),
    (600, "Medium", "Approve with standard terms"),
    (500, "High", "Approve with higher interest rate or shorter term"),
    (300, "Very High", "Decline or require substantial collateral")
]

def calculate_credit_score(prob_default, app_data=None, threshold=0.5):
    """Calculate credit score with dynamic risk adjustments."""
    if prob_default > 0.7:
        base_score = 300 + int((1 - prob_default) * 200)  # 300-500
    elif prob_default > 0.5:
        base_score = 500 + int((0.7 - prob_default) * 300)  # 500-650
    elif prob_default > threshold:
        base_score = 650 + int((0.5 - prob_default) * 300)  # 650-800
    else:
        base_score = 800 + int((0.3 - prob_default) * 200)  # 800-850
    
    return min(max(base_score, 300), 850)

def preprocess_new_application(data_dict, label_encoders, categorical_cols):
    """Preprocess raw application data for model prediction."""
    if "client_name" in data_dict:
        data_dict = {k: v for k, v in data_dict.items() if k != "client_name"}
        
    expected_columns = [
        'age', 'income', 'loan_amount', 'interest_rate', 'customer_tenure',
        'avg_days_late_current', 'industry_sector', 'credit_type',
        'has_guarantee', 'guarantee_type', 'repayment_frequency', 'turnover'
    ]
    
    df_new = pd.DataFrame(columns=expected_columns)
    
    for col in expected_columns:
        df_new[col] = [data_dict.get(col, 0)]
    
    for col in categorical_cols:
        val = str(df_new[col].iloc[0])
        if val not in label_encoders[col].classes_:
            val = "Unknown"
        try:
            df_new[col] = label_encoders[col].transform([val])[0]
        except ValueError:
            df_new[col] = label_encoders[col].transform(["Unknown"])[0]

    return df_new.drop(columns=["unpaid_amount", "num_late_payments_current"], errors="ignore")

def score_credit_application(app_data, model, label_encoders, categorical_cols, risk_levels=RISK_LEVELS):
    """Generate a complete credit assessment."""
    try:
        X_new = preprocess_new_application(app_data, label_encoders, categorical_cols)
        prob_default = model.predict_proba(X_new)[0][1]
        score = calculate_credit_score(prob_default, app_data)
        
        return {
            "client_name": app_data.get("client_name", "Client"),
            "credit_score": score,
            "default_probability": float(prob_default),
            "recommendation": "Approve" if prob_default < 0.5 else "Review"
        }
        
    except Exception as e:
        logging.error(f"Error processing application: {e}")
        return {"error": str(e)}

# Example Usage
if __name__ == "__main__":
    print("\nRunning example application...")
    try:
        with open('credit_scoring_model.pkl', 'rb') as f:
            model = pickle.load(f)
    except FileNotFoundError:
        print("Error: Model file not found. Train the model first.")
        exit()
    
    new_application = {
        "client_name": "Eric Davis",
        "age": 42,
        "income": 75000,
        "loan_amount": 25000,
        "interest_rate": 8.5,
        "customer_tenure": 5,
        "avg_days_late_current": 2,
        "industry_sector": "Technology",
        "credit_type": "Business Line of Credit",
        "has_guarantee": True,
        "guarantee_type": "Property",
        "repayment_frequency": "Monthly",
        "turnover": 1000000,
    }
    
    scoring_result = score_credit_application(
        new_application,
        model,
        label_encoders,
        categorical_features
    )
    
    print("\nScoring Result:")
    display(pd.DataFrame([scoring_result]))
